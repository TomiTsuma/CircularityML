{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4a699f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2aada859",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:/Users/Paylend/Documents/Circularity/object_detection/model/model/model.tf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33a5093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16bc89c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "tfModel = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "114b1cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TFLiteConverterV2 in module tensorflow.lite.python.lite:\n",
      "\n",
      "class TFLiteConverterV2(TFLiteFrozenGraphConverterV2)\n",
      " |  TFLiteConverterV2(funcs, trackable_obj=None)\n",
      " |  \n",
      " |  Converts a TensorFlow model into TensorFlow Lite model.\n",
      " |  \n",
      " |  Attributes:\n",
      " |    optimizations: Experimental flag, subject to change. Set of optimizations to\n",
      " |      apply. e.g {tf.lite.Optimize.DEFAULT}. (default None, must be None or a\n",
      " |      set of values of type `tf.lite.Optimize`)\n",
      " |    representative_dataset: A generator function used for integer quantization\n",
      " |      where each generated sample has the same order, type and shape as the\n",
      " |      inputs to the model. Usually, this is a small subset of a few hundred\n",
      " |      samples randomly chosen, in no particular order, from the training or\n",
      " |      evaluation dataset. This is an optional attribute, but required for full\n",
      " |      integer quantization, i.e, if `tf.int8` is the only supported type in\n",
      " |      `target_spec.supported_types`. Refer to `tf.lite.RepresentativeDataset`.\n",
      " |      (default None)\n",
      " |    target_spec: Experimental flag, subject to change. Specifications of target\n",
      " |      device, including supported ops set, supported types and a set of user's\n",
      " |      defined TensorFlow operators required in the TensorFlow Lite runtime.\n",
      " |      Refer to `tf.lite.TargetSpec`.\n",
      " |    inference_input_type: Data type of the input layer. Note that integer types\n",
      " |      (tf.int8 and tf.uint8) are currently only supported for post training\n",
      " |      integer quantization and quantization aware training. (default tf.float32,\n",
      " |      must be in {tf.float32, tf.int8, tf.uint8})\n",
      " |    inference_output_type: Data type of the output layer. Note that integer\n",
      " |      types (tf.int8 and tf.uint8) are currently only supported for post\n",
      " |      training integer quantization and quantization aware training. (default\n",
      " |      tf.float32, must be in {tf.float32, tf.int8, tf.uint8})\n",
      " |    allow_custom_ops: Boolean indicating whether to allow custom operations.\n",
      " |      When False, any unknown operation is an error. When True, custom ops are\n",
      " |      created for any op that is unknown. The developer needs to provide these\n",
      " |      to the TensorFlow Lite runtime with a custom resolver. (default False)\n",
      " |    experimental_new_converter: Experimental flag, subject to change. Enables\n",
      " |      MLIR-based conversion. (default True)\n",
      " |    experimental_new_quantizer: Experimental flag, subject to change. Enables\n",
      " |      MLIR-based quantization conversion instead of Flatbuffer-based conversion.\n",
      " |      (default True)\n",
      " |    experimental_enable_resource_variables: Experimental flag, subject to\n",
      " |      change. Enables resource variables to be converted by this converter. This\n",
      " |      is only allowed if from_saved_model interface is used. (default False)\n",
      " |  \n",
      " |  Example usage:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Converting a SavedModel to a TensorFlow Lite model.\n",
      " |    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
      " |    tflite_model = converter.convert()\n",
      " |  \n",
      " |  # Converting a tf.Keras model to a TensorFlow Lite model.\n",
      " |  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
      " |  tflite_model = converter.convert()\n",
      " |  \n",
      " |  # Converting ConcreteFunctions to a TensorFlow Lite model.\n",
      " |  converter = tf.lite.TFLiteConverter.from_concrete_functions([func], model)\n",
      " |  tflite_model = converter.convert()\n",
      " |  \n",
      " |  # Converting a Jax model to a TensorFlow Lite model.\n",
      " |  converter = tf.lite.TFLiteConverter.experimental_from_jax([func], [[\n",
      " |      ('input1', input1), ('input2', input2)])\n",
      " |  tflite_model = converter.convert()\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TFLiteConverterV2\n",
      " |      TFLiteFrozenGraphConverterV2\n",
      " |      TFLiteConverterBaseV2\n",
      " |      TFLiteConverterBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, funcs, trackable_obj=None)\n",
      " |      Constructor for TFLiteConverter.\n",
      " |      \n",
      " |      Args:\n",
      " |        funcs: List of TensorFlow ConcreteFunctions. The list should not contain\n",
      " |          duplicate elements.\n",
      " |        trackable_obj: tf.AutoTrackable object associated with `funcs`. A\n",
      " |          reference to this object needs to be maintained so that Variables do not\n",
      " |          get garbage collected since functions have a weak reference to\n",
      " |          Variables. This is only required when the tf.AutoTrackable object is not\n",
      " |          maintained by the user (e.g. `from_saved_model`).\n",
      " |  \n",
      " |  convert(self)\n",
      " |      Converts a TensorFlow GraphDef based on instance variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The converted data in serialized format.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          No concrete functions is specified.\n",
      " |          Multiple concrete functions are specified.\n",
      " |          Input shape is not specified.\n",
      " |          Invalid quantization parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  experimental_from_jax(serving_funcs, inputs) from builtins.type\n",
      " |      Creates a TFLiteConverter object from a Jax model with its inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        serving_funcs: A array of Jax functions with all the weights applied\n",
      " |          already.\n",
      " |        inputs: A array of Jax input placeholders tuples list, e.g.,\n",
      " |          jnp.zeros(INPUT_SHAPE). Each tuple list should correspond with the\n",
      " |          serving function.\n",
      " |      \n",
      " |      Returns:\n",
      " |        TFLiteConverter object.\n",
      " |  \n",
      " |  from_concrete_functions(funcs, trackable_obj=None) from builtins.type\n",
      " |      Creates a TFLiteConverter object from ConcreteFunctions.\n",
      " |      \n",
      " |      Args:\n",
      " |        funcs: List of TensorFlow ConcreteFunctions. The list should not contain\n",
      " |          duplicate elements. Currently converter can only convert a single\n",
      " |          ConcreteFunction. Converting multiple functions is under development.\n",
      " |        trackable_obj:   An `AutoTrackable` object (typically `tf.module`)\n",
      " |          associated with `funcs`. A reference to this object needs to be\n",
      " |          maintained so that Variables do not get garbage collected since\n",
      " |          functions have a weak reference to Variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        TFLiteConverter object.\n",
      " |      \n",
      " |      Raises:\n",
      " |        Invalid input type.\n",
      " |  \n",
      " |  from_keras_model(model) from builtins.type\n",
      " |      Creates a TFLiteConverter object from a Keras model.\n",
      " |      \n",
      " |      Args:\n",
      " |        model: tf.Keras.Model\n",
      " |      \n",
      " |      Returns:\n",
      " |        TFLiteConverter object.\n",
      " |  \n",
      " |  from_saved_model(saved_model_dir, signature_keys=None, tags=None) from builtins.type\n",
      " |      Creates a TFLiteConverter object from a SavedModel directory.\n",
      " |      \n",
      " |      Args:\n",
      " |        saved_model_dir: SavedModel directory to convert.\n",
      " |        signature_keys: List of keys identifying SignatureDef containing inputs\n",
      " |          and outputs. Elements should not be duplicated. By default the\n",
      " |          `signatures` attribute of the MetaGraphdef is used. (default\n",
      " |          saved_model.signatures)\n",
      " |        tags: Set of tags identifying the MetaGraphDef within the SavedModel to\n",
      " |          analyze. All tags in the tag set must be present. (default\n",
      " |          {tf.saved_model.SERVING} or {'serve'})\n",
      " |      \n",
      " |      Returns:\n",
      " |        TFLiteConverter object.\n",
      " |      \n",
      " |      Raises:\n",
      " |        Invalid signature keys.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from TFLiteConverterBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(tf.lite.TFLiteConverter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fae8b293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tfModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96e4e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle. dump(tfModel, open('tfModel.tflite', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2751f70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3282736"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(path + \".tfLite.tflite\", \"wb\").write(tfModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2892f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2='C:/Users/Paylend/Documents/Circularity/object_detection/new_graph/frozen_inference_graph.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "529c3685",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m converter \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFLiteConverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_frozen_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_arrays\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43moutput_arrays\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\lite\\python\\lite.py:2528\u001b[0m, in \u001b[0;36mTFLiteConverter.from_frozen_graph\u001b[1;34m(cls, graph_def_file, input_arrays, output_arrays, input_shapes)\u001b[0m\n\u001b[0;32m   2525\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease freeze the graph using freeze_graph.py.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2527\u001b[0m \u001b[38;5;66;03m# Get input and output tensors.\u001b[39;00m\n\u001b[1;32m-> 2528\u001b[0m input_tensors \u001b[38;5;241m=\u001b[39m \u001b[43m_get_tensors_from_tensor_names\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2529\u001b[0m \u001b[43m    \u001b[49m\u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_arrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2530\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m _get_tensors_from_tensor_names(\n\u001b[0;32m   2531\u001b[0m     sess\u001b[38;5;241m.\u001b[39mgraph, output_arrays)\n\u001b[0;32m   2532\u001b[0m _set_tensor_shapes(input_tensors, input_shapes)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\lite\\python\\util.py:151\u001b[0m, in \u001b[0;36mget_tensors_from_tensor_names\u001b[1;34m(graph, tensor_names)\u001b[0m\n\u001b[0;32m    149\u001b[0m tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    150\u001b[0m invalid_tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m tensor_names:\n\u001b[0;32m    152\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, six\u001b[38;5;241m.\u001b[39mstring_types):\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid type for a tensor name in the provided graph. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected type for a tensor name is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, instead got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for tensor name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    156\u001b[0m                          \u001b[38;5;28mtype\u001b[39m(name), name))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d820d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87424e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c417a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.lite.TFLiteConverter.from_frozen_graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
